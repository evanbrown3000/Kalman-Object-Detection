{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZcqD4NLdnf4"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "from create_and_restore_model import create_and_restore_model\n",
    "%matplotlib inline\n",
    "\n",
    "num_classes = 1\n",
    "pipeline_config = '/home/evan/Desktop/Tensorflow/models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config'\n",
    "checkpoint_path = './fine_tuned_ckpts/ckpt--1' #set to latest ckpt, remove -\n",
    "(orig_width ,orig_height) = (960,544)\n",
    "(new_width, new_height) = (640,640)\n",
    "hand_class_id = 1\n",
    "num_classes = 1\n",
    "CATEGORY_INDEX = {hand_class_id: {'id': hand_class_id, 'name': 'hand'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghDAsqfoZvPh"
   },
   "source": [
    "# Create model and restore weights from ckpt for all but last layer\n",
    "\n",
    "In this cell we build a single stage detection architecture (RetinaNet) and restore all but the classification layer at the top (which will be automatically randomly initialized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = \\\n",
    "create_and_restore_model(pipeline_config = '/home/evan/Desktop/Tensorflow/models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config', \n",
    "                        checkpoint_path = './fine_tuned_ckpts/ckpt--1', \n",
    "                        new_height = 640, \n",
    "                        new_width = 640, \n",
    "                        hand_class_id = 1, \n",
    "                        num_classes = 1,\n",
    "                        restore_classification_head = True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHlXL1x_Z3tc"
   },
   "source": [
    "# Run inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "kalman = cv2.KalmanFilter(4,2)\n",
    "kalman.measurementMatrix = np.array(\n",
    "    [[1, 0, 0, 0],\n",
    "     [0, 1, 0, 0]], np.float32)\n",
    "kalman.transitionMatrix = np.array(\n",
    "    [[1, 0, 1, 0],\n",
    "     [0, 1, 0, 1],\n",
    "     [0, 0, 1, 0],\n",
    "     [0, 0, 0, 1]], np.float32)\n",
    "kalman.processNoiseCov = np.array( \n",
    "    [[1, 0, 0, 0],\n",
    "     [0, 1, 0, 0],\n",
    "     [0, 0, 1, 0],\n",
    "     [0, 0, 0, 1]] , np.float32) * 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def detect(input_tensor):\n",
    "  \"\"\"Run detection on an input image.\n",
    "\n",
    "  Args:\n",
    "    input_tensor: A [1, height, width, 3] Tensor of type tf.float32.\n",
    "      Note that height and width can be anything since the image will be\n",
    "      immediately resized according to the needs of the model within this\n",
    "      function.\n",
    "\n",
    "  Returns:\n",
    "    A dict containing 3 Tensors (`detection_boxes`, `detection_classes`,\n",
    "      and `detection_scores`).\n",
    "  \"\"\"\n",
    "  preprocessed_image, shapes = detection_model.preprocess(input_tensor)\n",
    "  prediction_dict = detection_model.predict(preprocessed_image, shapes)\n",
    "  return detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "def plot_detections(image_np,\n",
    "                    boxes,\n",
    "                    classes,\n",
    "                    scores,\n",
    "                    CATEGORY_INDEX,\n",
    "                    figsize=(12, 16),\n",
    "                    image_name=None):\n",
    "  \"\"\"Wrapper function to visualize detections.\n",
    "\n",
    "  Args:\n",
    "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    boxes: a numpy array of shape [N, 4]\n",
    "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
    "      and match the keys in the label map.\n",
    "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
    "      this function assumes that the boxes to be plotted are groundtruth\n",
    "      boxes and plot all boxes as black with no classes or scores.\n",
    "    CATEGORY_INDEX: a dict containing category dictionaries (each holding\n",
    "      category index `id` and category name `name`) keyed by category indices.\n",
    "    figsize: size for the figure.\n",
    "    image_name: a name for the image file.\n",
    "  \"\"\"\n",
    "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      boxes,\n",
    "      classes,\n",
    "      scores,\n",
    "      CATEGORY_INDEX,\n",
    "      use_normalized_coordinates=True,\n",
    "      min_score_thresh=0.0)\n",
    "  return image_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcE6OwrHQJya"
   },
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0) #use webcam\n",
    "last_measurement = None\n",
    "last_box = None\n",
    "last_score = None\n",
    "last_class = None\n",
    "last_prediction = None\n",
    "first_good_detection = False\n",
    "label_id_offset = 1\n",
    "kalman_counter = 1\n",
    "\n",
    "while(True):\n",
    "    #take frames until escape button\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "      print('unable to read frame')\n",
    "      continue\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27: #escape\n",
    "        break\n",
    "    \n",
    "    if kalman_counter == 1:\n",
    "      print('ran model')\n",
    "      input_tensor = tf.convert_to_tensor([frame], dtype=tf.float32)\n",
    "      detections = detect(input_tensor)\n",
    "      box = detections['detection_boxes'][0][0].numpy()#[ymin, xmin, ymax, xmax]\n",
    "      class_ = detections['detection_classes'][0][0].numpy()\n",
    "      if class_ is None:\n",
    "        class_ = np.array([0])\n",
    "      score = detections['detection_scores'][0][0].numpy()\n",
    "      print(score)\n",
    "      #bbox center coords, height, width\n",
    "      x = box[3]-box[1]\n",
    "      y = box[2]-box[0]\n",
    "      h = box[2]-box[0]\n",
    "      w = box[3]-box[1]\n",
    "      if first_good_detection:\n",
    "        kalman_counter = 0\n",
    "\n",
    "    #wait for at least .9 confidence detection, then use Kalman\n",
    "    if first_good_detection is False and score > .9:\n",
    "      print('first good det')\n",
    "      first_good_detection = True\n",
    "\n",
    "    if first_good_detection is True:\n",
    "      if last_measurement is None:\n",
    "        kalman.statePre = np.array([[x], [y], [0], [0]], np.float32)\n",
    "        kalman.statePost = np.array([[x], [y], [0], [0]], np.float32)\n",
    "      else: \n",
    "        print('using Kalman')\n",
    "        kalman.correct(np.array([[x], [y]], np.float32))\n",
    "        prediction = kalman.predict().reshape(4)\n",
    "        box = prediction\n",
    "        class_ = last_class\n",
    "        kalman_counter += 1\n",
    "      \n",
    "    #TODO: look @ below line\n",
    "    last_class = class_\n",
    "    last_measurement = np.array([[x], [y]], np.float32)\n",
    "\n",
    "    # print(box)\n",
    "    frame = plot_detections(\n",
    "        frame,\n",
    "        box[np.newaxis, :],\n",
    "        np.array([class_.astype(np.uint32) + label_id_offset]),\n",
    "        np.array([score]),\n",
    "        CATEGORY_INDEX, figsize=(15, 20), image_name='frame with detections')\n",
    "    cv2.imshow('detections on frame', frame)\n",
    "\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "interactive_eager_few_shot_od_training_colab.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "8ef37928cbe5219b2fcf8404ea29b31b1a966345f86328e41ae7ac18a87552f8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
